---
layout: post
title:  "[정리글] 추천시스템 3.0: 딥러닝 후기시대에서 바이어스, 그래프, 그리고 인과관계의 중요성"
date:   2020-02-01 19:31:29 +0900
categories: RecSys
tags : [Bias, GNN, Causality, Counterfactual]
toc: true
toc_sticky: true
---

> DEVIEW'20에서 [발표된 내용](https://tv.naver.com/v/16970750)을 정리한 글입니다.

# 0. 요약
- 네이버 LINE Wallet 쿠폰 추천 시스템 구축시 고려한 점들을 발표했다.
- 기존 추천시스템에서 중요하지만 잘 안다뤘던 부분을 다뤘다.
- Positinal Bias를 해소하는 부분과 모델 테스트 시스템이 볼만하다.


# 1. 추천시스템 배경

- 추천 시스템 역사를 소개하면서 3단계로 나누고 있다.

    ```
    1단계 : CF 기반의 추천
    2단계: 딥러닝 기반의 추천
    3단계: 인과관계를 중심으로한 추천
    ```

- 3단계의 특징으로 Positional Bias 줄이기, 그래프 이용하기, 인과관계를 고려하기를 들었다.
- 발표를 들었을 때 인과관계를 평가에만 고려한 걸로 보인다.
    - 모델에 반영 수준은 아니다.

- Line Walllet 탭
<img src="https://www.dropbox.com/s/x551g2ul4qp29ar/Untitled.png?raw=1">

# 2. Bias Reduction

- 모듈(쿠폰, 카드, 포인트, 찌라시)의 순서 매기는 태스크를 하고 있다.
- 그런데 모듈에 있는 콘텐츠 내용과 관련없이 50%가 첫 번째 모듈을 클릭한다.
    - 상단에 위치하면 클릭 로그가 많아져서 다시 상단에 위치하고
    - 하단에 위치하면 클릭 로그가 적여져서 다시 하단에 위치되는
    - 빈익빈 부익부 현상이 나타난다.

- Bias Reduction을 위해서 시도한 4가지 방법을 소개한다.

## 방법 1. 랜덤 데이터로 학습하기

- Random Exploration : 모델의 결과와 상관 없이 무작위로 모듈을 추천해보는 방법.
- 일부 데이터를 사용할 수 밖에 없다.

<img src="https://www.dropbox.com/s/b6ekmxrb146unmm/Untitled%201.png?raw=1">

## 방법 2. CTR Loss Weight

- 10분 22초 부터
- 전체 데이터를 사용하는 방법
- Loss를 구할 때 CTR에 따라 다른 Weight을 준다.
- 의도 부분이 다음 슬라이드(방법)과 바뀌었다고 한다. (* 첨부한 사진은 임의로 순서를 바꿨다.)

<img src="https://www.dropbox.com/s/7skhluoy7joqpsk/Untitled%202.png?raw=1" width="50%" height="50%">
<img src="https://www.dropbox.com/s/xpaqoljpbqyjsbw/Untitled%203.png?raw=1" height="50%">


## 방법3. CTR Mini-Batch

- 12분 부터
- 방법2에서 Imbalance 문제가 있었다.

    → 미니 배치를 구성할 때 CTR에 비례하게 구성한다.

<p float="left">
    <img src="https://www.dropbox.com/s/vir52w1mo6zxgj3/Untitled%204.png?raw=1" width="50%" height="50%">
    <img src="https://www.dropbox.com/s/2t7dtkhga2l1v8t/Untitled%205.png?raw=1" height="50%">
</p>

## 방법4. Explorative Labeling

- 방법 1과 Thomson Sampling을 썼다는 점 외에 다른게 있는가 싶다.
<img src="https://www.dropbox.com/s/ki50iiy3uksmep9/Untitled%206.png?raw=1" height="50%">

# 3. GNN for Recommendation

- 18분 40초부터.
- 앞에서 이야기한 모델은 모듈 추천 모델이었다.
- 모듈 안에 아이템 추천은 GNN으로 한다.
    - 이유와 구조를 들어보자.

- 기존 딥러닝 기반 추천 시스템 구조도 (CTR Prediction Task)
    - 이런 모델은 Cold Start 문제와 Diversity를 잘 해결하지 못한다.
    - 데이터 포인트가 독립적으로 존재한다.
    - 새로운 쿠폰에 대한 데이터가 없기 때문에(추천이 안되어)
    - 인기 있는 아이템 위주로 추천되고 Diversity 저하로 이어진다.
<img src="https://www.dropbox.com/s/bd4odogkeuugcq4/Untitled%207.png?raw=1" width="60%" height="60%">

Goal : CTR과 Diversity 두 마리 토끼 잡기

- 그래프 기반 추천 시스템
    - 연결을 학습한다.
    - 유저와 쿠폰의 피쳐를 뽑은 다음, GNN 기반으로 연결정보를 추출한다.
    → 콜드 스타트 문제를 완화할 수 있다. 정말?
<img src="https://www.dropbox.com/s/1w97whv4v5d582h/Untitled%208.png?raw=1" width="60%" height="60%">

- Diveristy에 관련해서 그림과 같은 결과를 얻었다.
    - 그래프 모델에서 과거 2주간 인기있던 아이템의 비중이 적어졌다는 뜻.

<img src="https://www.dropbox.com/s/hgecjxtjy3awcmg/Untitled%209.png?raw=1" width="60%" height="60%">


# 4. Counterfactual Evaluation

- 추천 문제는 다른 딥러닝 태스크와 좀 다르다.
    - 맥락에 따라 Label이 다를 수 있다.
    - 개와 고양이 레이블은 바뀌지 않지만 유저는 콘텍스트에 따라 클릭할 수도, 안 할수도 있다.
    - 그래서 오프라인과 온라인 지표가 정렬되지 않는다.
    - 저번주에는 클릭하지 않았을 사람이 이번주에는 콘텍스트가 바뀌어 클릭할 수 있기 때문이다.

- " 오프라인 지표를 선택해서 최적화하자" 보다는
    - 온라인 지표의 성능에 영향을 미치는 요소를 이용해서 모델 튜닝, 서빙하자.

## 방법 1. 온라인 지표에 영향을 주는 요소를 알아내자
- 여전히 간극이 있고 온라인 자체에서 모델 테스트가 필요하다.
- Counterfactual 평가 방법인 IPS(Inverse Propensity Score)와 CAB(Continuous Adaptive Blending)를 사용했다.
- [CAB 논문](http://proceedings.mlr.press/v97/su19a/su19a.pdf)
- 표에는 없지만 Direct Method도 사용했다고 한다.

<img src="https://www.dropbox.com/s/q29utq5abn4yjck/Untitled%2010.png?raw=1" width="60%" height="60%">

## 방법 2. 온라인 - 오프라인 테스트를 합쳐보자

- 1부리그(온라인 테스트)와 2부리그(오프라인 테스트)를 나누고
- 1부리그 하위 모델과 2부리그 상위 모델이 승강전을 한다.

## 원하는 형태

- As-is 인지 To-be 인지 모르겠지만 원하는 형태는

<img src="https://www.dropbox.com/s/d9m7uacma5ffvju/Untitled%2011.png?raw=1" width="60%" height="60%">

# 5. 결론

<img src="https://www.dropbox.com/s/1t3dd920qwbtm33/Untitled%2012.png?raw=1" width="60%" height="60%">
