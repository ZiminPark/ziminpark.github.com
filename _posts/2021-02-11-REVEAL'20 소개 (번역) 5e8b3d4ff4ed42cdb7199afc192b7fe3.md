---
layout: post
title:  "[번역글] REVEAL'20 Workshop Introduction"
date:   2020-02-11 19:31:29 +0900
categories: RecSys
tags : [Bandit, REVEAL, RL, Counterfactual]
toc: true
toc_sticky: true
---

><a href="https://sites.google.com/view/reveal2020/home" target="_blank">REVEAL'20 Home</a>을 번역한 글입니다. 문장이 길고 복문이 많아서 짧은 단문으로 고쳐 썼습니다.

## <mark>주요주장</mark>

1. **추천 시스템을 모델링 할 때 유저와 시스템이 Interactive하고 multi-step descision making하다는 특징을 살자.**

2. **지도 학습에서 유래한 Proxy Offline Metric 대신 Logged Interaction Data를 활용할 수 있는 Counterfactual Evaluation을 하자.**

3. **1,2를 학계에서도 연구할 수 있게 Simulator와 Open datasets을 만들자.**

<br>

## <mark>본문</mark>
최신 추천 시스템들은 설계 및 개선이 어렵기로 악명이 높습니다. Interactive 하고 Dynamic 하기 때문인데요. 사용자와 시스템 간에 발생하는 일련의 상호작용(interactions)에서
다단계 의사 결정 프로세스(multi-step decision making process) 수반하기 때문에 이런 특징을 지니게 됩니다.
상호작용에서 생기는 보상 신호를 활용하고, 확장 가능하면서 성능이 뛰어난 추천 추론 모델을 만드는 일은 중요한 과제입니다.
상호작용은 통상적으로 문제를 쉽게 다루기 위해 독립적으로 다뤄집니다.
하지만 추천 시스템을 더욱 개선하기 위해서는 추천에 대한 delayed effect를 고려해야 하고, 사용자의 장기 만족을 위한 reasoning과 planning을 고려하기 시작해야 합니다.
이를 위해 워크샵에서는 추천 시스템에 다양한 형태의 사용자 피드백을 효과적으로 적용했거나 사용자의 장기적인 경험을 최적화한 연구(contributions)를 초청합니다.

또한 추천 시스템의 interactive한 성질 때문에 평가하기 어렵기로 악명이 높습니다.
현업에서 시스템을 평가할 때, 종종 새로운 알고리즘의 오프라인 결과와 온라인 결과 사이에서 상당한 차이를 관찰하기 때문에 주로 A/B 테스트 같은 온라인 방법에 의존하는 경향이 있습니다.
안타깝게도 온라인 평가가 항상 가능하지는 않으며 비용이 많이 듭니다.
반면, 오프라인 평가는 추천 시스템을 비교할 수 있는 확장 가능한 방법을 제시하고 산업 문제를 학계에서 다룰 수 있게 합니다.

그동안의 추천 시스템은 Regression Metrics(MSE, Log Likelihood), Classifiaction Metrics(AUC),
Ranking Metrics(precision@k, NDCG) 같은 지도 학습에서 유래한 Proxy Offline Metrics들을 통해 평가되어 왔습니다.
최근 추천 시스템 연구는 Offline A/B 테스팅을 위한 Counterfactual Inference 와의 연결점을 만들고 있습니다.
이를 위해 Logged Interaction Data를 재사용하거나 민감한 개인 정보 문제를 피하기 위해 시뮬레이터를 사용하기도 합니다.

이런 맥락에서, 추천 시스템을 설계하고 평가하는 문제를 다시 생각해보는 워크샵을 구성하기 좋은 시기라 생각합니다.
이를 통해 학계와 산업계를 망라한 커뮤니티가 올바른 문제, *각 사용자에게 가장 영향력있는 추천을 하고 있는지*,를 풀고 있는지 확인하려 합니다.

<br>

## <mark>워크샵 주제</mark>
이번 워크샵은 열띤 참여가 있었던
<a href="https://www.google.com/url?q=https%3A%2F%2Fsites.google.com%2Fview%2Freveal2018%2Fhome&sa=D&sntz=1&usg=AFQjCNFL2KhYCb1UXxD4tkFJITqSXjFgvQ" target="_blank">REVEAL’18</a>와
<a href="https://www.google.com/url?q=https%3A%2F%2Fsites.google.com%2Fview%2Freveal2019%2Fhome&sa=D&sntz=1&usg=AFQjCNGNNg7W6lEu37vasKirngi7nO9wng" target="_blank">REVEAL’19</a>의
 follow-up 입니다.
다음 주제에 대한 연구를 계속 확장해나가기를 제안합니다.


- **Reinforcement learning and bandits for recommendation**
- **Robust estimators and counterfactual evaluation**
- **Using simulation for recommender systems evaluation**
- **Open datasets and new offline metrics**

The benefits of this workshop will be:

- **To bridge the gap between academia and industry through new datasets and methods**
- **To increase the productivity of all practitioners in their development of recommender systems**

Organizers:

- [Thorsten Joachims](http://www.google.com/url?q=http%3A%2F%2Fwww.cs.cornell.edu%2Fpeople%2Ftj%2F&sa=D&sntz=1&usg=AFQjCNEPNtqvJjc2x-r4hvCel4PnMrGPhg), Information Science and Computer Science, Cornell University
- [Adith Swaminathan](https://www.google.com/url?q=https%3A%2F%2Fwww.microsoft.com%2Fen-us%2Fresearch%2Fpeople%2Fadswamin%2F&sa=D&sntz=1&usg=AFQjCNHE8Nalw7qbDTckSWLh7GcgQtmhpg), Deep Learning Technology Center, Microsoft Research
- [Maria Dimakopoulou](http://www.google.com/url?q=http%3A%2F%2Fstanford.edu%2F~madima%2F&sa=D&sntz=1&usg=AFQjCNE9JmP_e_OXrgvpDlzaTp8b2F9fNQ) and [Yves Raimond](https://www.google.com/url?q=https%3A%2F%2Fwww.linkedin.com%2Fin%2Fyvesr%2F&sa=D&sntz=1&usg=AFQjCNHfQBa_Urk9aClGqYMrws8FJJsV7A), Netflix Research
- [Olivier Koch](https://www.google.com/url?q=https%3A%2F%2Fwww.linkedin.com%2Fin%2Folivier-koch%2F&sa=D&sntz=1&usg=AFQjCNGV0YUrkyeS7Cp2KzYOYDY2oxJeiQ) and [Flavian Vasile](https://www.google.com/url?q=https%3A%2F%2Fwww.linkedin.com%2Fin%2Fflavianv%2F&sa=D&sntz=1&usg=AFQjCNHoYB23IuwmKpIO2rRNnIR3W8z3Zg), R&D, Criteo
